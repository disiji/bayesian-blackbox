{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################CONSTANTS######################################\n",
    "METRIC = 'accuracy'\n",
    "MODE = 'min'\n",
    "\n",
    "RUNS = 100\n",
    "LOG_FREQ = 100\n",
    "threshold = 0.98  # threshold for x-axis cutoff\n",
    "\n",
    "\n",
    "COLOR = {'non-active_no_prior': '#1f77b4',\n",
    "         'ts_uniform': 'red',#'#ff7f0e',\n",
    "         'ts_informed': 'green',\n",
    "         'epsilon_greedy_no_prior': 'tab:pink',\n",
    "         'bayesian_ucb_no_prior': 'cyan',\n",
    "         }\n",
    "\n",
    "\n",
    "TOPK_METHOD_NAME_DICT = {'non-active_no_prior': 'Non-active',\n",
    "                          #                         'non-active_uniform': 'non-active_uniform',\n",
    "                          #                         'non-active_informed': 'non-active_informed',\n",
    "                          'ts_uniform': 'MP-TS',\n",
    "                          'ts_informed': 'MP-TS (informative)',\n",
    "                          'epsilon_greedy_no_prior': 'Epsilon greedy',\n",
    "                          'bayesian_ucb_no_prior': 'Bayesian UCB',\n",
    "                          }\n",
    "\n",
    "LINEWIDTH = 13.97\n",
    "\n",
    "\n",
    "######################################CONSTANTS######################################\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "import argparse\n",
    "from typing import Dict, Any\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "from data_utils import DATASIZE_DICT, FIGURE_DIR, RESULTS_DIR\n",
    "from data_utils import DATASET_NAMES, TOPK_DICT\n",
    "\n",
    "import matplotlib;matplotlib.rcParams['font.family'] = 'serif'\n",
    "\n",
    "RESULTS_DIR = RESULTS_DIR + 'active_learning_topk/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topk_accuracy(ax: mpl.axes.Axes,\n",
    "                       experiment_name: str,\n",
    "                       topk: int,\n",
    "                       eval_metric: str,\n",
    "                       pool_size: int,\n",
    "                       threshold: float,\n",
    "                       plot_informed: bool = False) -> None:\n",
    "    \n",
    "    if plot_informed:\n",
    "        benchmark = 'ts_informed'\n",
    "        method_list = {'ts_informed': 'TS (informative)',\n",
    "                       'ts_uniform': 'TS (uninformative)', }\n",
    "    else:\n",
    "        benchmark = 'ts_uniform'\n",
    "        method_list = {#'non-active_no_prior', \n",
    "                       'ts_uniform', \n",
    "                       'epsilon_greedy_no_prior', \n",
    "                       'bayesian_ucb_no_prior'}\n",
    "        # method_list = {'non-active_no_prior', 'ts_uniform'}\n",
    "\n",
    "    for method in method_list:\n",
    "        metric_eval = np.load(\n",
    "            RESULTS_DIR + experiment_name + ('%s_%s.npy' % (eval_metric, method))).mean(axis=0)\n",
    "        x = np.arange(len(metric_eval)) * LOG_FREQ / pool_size\n",
    "        if topk == 1:\n",
    "            if plot_informed:\n",
    "                label = method_list[method]\n",
    "            else:\n",
    "                label = METHOD_NAME_DICT[method]\n",
    "        else:\n",
    "            label = TOPK_METHOD_NAME_DICT[method]\n",
    "        ax.plot(x, metric_eval, label=label, color=COLOR[method], linewidth=3)\n",
    "\n",
    "        if method == benchmark:\n",
    "            if method == benchmark:\n",
    "                if max(metric_eval) > threshold:\n",
    "                    cutoff = list(map(lambda i: i > threshold, metric_eval.tolist()[10:])).index(True) + 10\n",
    "                    cutoff = min(int(cutoff * 1.2), len(metric_eval) - 1)\n",
    "                else:\n",
    "                    cutoff = len(metric_eval) - 1\n",
    "\n",
    "    ax.set_xlim(0, cutoff * LOG_FREQ / pool_size)\n",
    "    ax.set_ylim(0, 1.0)\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    step = ((xmax - xmin) / 4.0001)\n",
    "    ax.xaxis.set_major_formatter(ticker.PercentFormatter(xmax=1))\n",
    "    ax.xaxis.set_ticks(np.arange(xmin, xmax + 0.001, step))\n",
    "    ax.yaxis.set_ticks(np.arange(0, 1.01, 0.20))\n",
    "    ax.tick_params(pad=0.25, length=1.5)\n",
    "\n",
    "    return ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
